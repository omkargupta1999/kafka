apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-{{ .Values.configMap.nameSuffix }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{ include "Epay_Operations_Service.labels" . | nindent 4 }}
{{ if $.Values.configMap.additionalLabels }}
    {{ toYaml $.Values.configMap.additionalLabels | nindent 4 }}
{{ end }}
{{ if $.Values.configMap.annotations }}
  annotations:
    {{ toYaml $.Values.configMap.annotations | nindent 4 }}
{{ end }}
data:
  application.yml: |
    server:
      servlet:
        context-path: /api/rns/v1
      port: 9097
    security:
      jwt:
        secret:
          issuer: sbi.epay
          key: bsrfgskjfhsdjkhkflkdlksdlfkskfwperip3ke3le3lmldrnkfnhiewjfejfokepfkldkfoikfokork3dklwedlsvflvkfkvlkdfvodkvcdokro3
      whitelist.urls: /webjars/, /actuator/health, /swagger-resources/, /v3/api-docs, /v3/api-docs/**, /swagger-ui/**, /index.html, /login
      cors:
        allowed:
          origins: "*"
        origin: https://preprod.epay.sbi
    spring:
      profiles:
        active: dev
      application:
        name: Operations Service
      # Db connectivity
      jpa:
        properties:
          hibernate:
            jdbc:
              batch_size: 1000
              order_updates: true
              order_inserts: true
              batch_versioned_data: true
              generate_statistics: true
            show-sql: true
            format_sql: true
        show-sql: true
      datasource:
        driver-class-name: oracle.jdbc.OracleDriver
        url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=EPAYDNSPREPRODNEW.sbiepay.sbi)(PORT=1524))(CONNECT_DATA= (SERVER=DEDICATED) (SERVICE_NAME=report.sbiepay.sbi)))
        username: PAYAGGOPERATION
        password: April_2025
    
      # Liquibase Properties
      liquibase:
        change-log: classpath:db/changelog/db.changelog-master.xml
        enabled: true
        drop-first: false
      kafka:
        bootstrapServers: pre-prod-kafka-cluster-kafka-bootstrap.pre-prod-kafka.svc.cluster.local:9092
            #Kafka consumer config
        consumer:
          groupId: operation-consumers
          keyDeserializer: org.apache.kafka.common.serialization.StringDeserializer
          valueDeserializer: org.apache.kafka.common.serialization.StringDeserializer
          autoOffsetReset: latest
          autoCommitInterval: 100
          enableAutoCommit: true
          sessionTimeoutMS: 300000
          requestTimeoutMS: 420000
          fetchMaxWaitMS: 200
          maxPollRecords: 5
          retryMaxAttempts: 3
          retryBackOffInitialIntervalMS: 10000
          retryBackOffMaxIntervalMS: 30000
          retryBackOffMultiplier: 2
          spring.json.trusted.packages: com.epay.operations
          numberOfConsumers: 10
        #Kafka producer config
        producer:
          acks: all
          retries: 3
          batchSize: 1000
          lingerMs: 1
          bufferMemory: 33554432
          keyDeserializer: org.apache.kafka.common.serialization.StringSerializer
          valueDeserializer: org.apache.kafka.common.serialization.StringSerializer
        #Kafka topic config
        topic:
          recon:
            file: ops_recon_file_topic
            record:
              match: ops_recon_record_matched_topic
              unmatched: ops_recon_record_unmatched_topic
              duplicate: ops_recon_record_duplicate_topic
              fail: ops_recon_fail_ack_topic
          payout: ops_payout_topic
          refund:
            adjust: ops_refund_adjust_detail_topic
            adjust.confirmation: ops_refund_adjust_confirmation_topic
          report:
            generation: ops_report_generation_topic
            confirmation: ops_report_confirmation_topic
          partitions: 4
          replicationFactor: 1
      servlet:
        multipart:
          max-file-size: 50MB
          max-request-size: 50MB
    spark:
      app:
        name: ${spring.application.name}
      master: local[*]
      #spark://api.dev.sbiepay.sbi:6443
      #spark.master can be:
      #  local[*] for local mode
      #  spark://host:port for Spark Standalone cluster

    logging:
      level:
        liquibase: DEBUG
        #org.apache.kafka: ERROR

    external:
      api:
        services:
          base:
            path:
              admin: http://admin-adminservice.pre-prod-admin.svc.cluster.local:9094/api/admin/v1

    aws:
      s3:
        url: https://s3store.bank.sbi/
        region: ap-south-1
        key: IDHJO1513FFMMNLPR9BC
        secret: avXqEPv5B_QqqPK0D1VJzP3pSyAA4x31Zu_KucQ9
        bucket: epay-nonprod-s3bucket

    #SFTP config
    sftp:
      #host: preprod.sfg.sbi
      host: localhost #sfg.sbiperf.bank.in
      port: 2222  #2201
      username: root #EPAY_CET_2501
      password: root #Statebank@345
      dir: /home/default/OPS
      session:
        timeout: 30000
        cacheSize: 5
    
    secret:
      key: encryptionKeyForFile134424
      salt: salt_54321
    
    scheduler:
      lockAtLeastFor: PT30S
      lockAtMostFor: PT10M
      cron:
        expression:
          sftp.recon.file: 0/5 * * * * *
          payout.generation.check: 0/5 * * * * *
          transaction.data.sync: 0/5 * * * * *
          payout.report: 0/5 * * * * *
          operation.data.purge: 0/5 * * * * *
    
    process:
      generation:
        batch:
          size: 1000
    payout:
      generation:
        time:
          interval: 60
    
    recon:
      process:
        runner:
          mode: JAVA
    
    flush:
      event:
        logs:
          maxBatchSize: 5000

    jdbc:
      insert:
        batchSize: 5000

    queue:
      batch:
        size:
          event: 5000
    
    #purgin retention day
    purge:
      retentionDays: 7
