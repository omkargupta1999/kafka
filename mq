./kafka-topics.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--list

bin/kafka-console-producer.sh --bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 --producer.config /tmp/strimzi-connect.properties --topic neft.outbound.kafka.topic



./kafka-console-producer.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--topic neft.outbound.kafka.topic


bin/kafka-console-consumer.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--topic neft.outbound.kafka.topic \
--from-beginning

bin/kafka-console-producer.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--command-config /opt/kafka/custom-config/kafka-connect.properties \
--topic neft.outbound.kafka.topic

bin/kafka-console-producer.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--producer.config /tmp/strimzi-connect.properties \
--topic neft.outbound.kafka.topic


==========================================

using the pod dev-kafka-connect-mq-test-connect-0


sh-5.1$ cd bin
sh-5.1$ ./kafka-console-producer.sh --bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 --producer.config /tmp/strimzi-connect.properties --topic neft.outbound.kafka.topic
[2026-01-17 07:23:26,297] WARN The path /opt/kafka/init is not a directory (org.apache.kafka.common.config.provider.DirectoryConfigProvider)
org.apache.kafka.common.KafkaException: Failed to construct kafka producer
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:476)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:297)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:324)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:309)
        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:99)
        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
Caused by: org.apache.kafka.common.KafkaException: Failed to create new NetworkClient
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:255)
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:163)
        at org.apache.kafka.clients.producer.KafkaProducer.newSender(KafkaProducer.java:526)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:465)
        ... 5 more
Caused by: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /tmp/kafka/cluster.truststore.p12 of type PKCS12
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.load(DefaultSslEngineFactory.java:380)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.<init>(DefaultSslEngineFactory.java:352)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory.createTruststore(DefaultSslEngineFactory.java:325)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory.configure(DefaultSslEngineFactory.java:169)
        at org.apache.kafka.common.security.ssl.SslFactory.instantiateSslEngineFactory(SslFactory.java:147)
        at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:100)
        at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:70)
        at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:193)
        at org.apache.kafka.common.network.ChannelBuilders.clientChannelBuilder(ChannelBuilders.java:82)
        at org.apache.kafka.clients.ClientUtils.createChannelBuilder(ClientUtils.java:120)
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:224)
        ... 8 more
Caused by: java.io.IOException: keystore password was incorrect
        at java.base/sun.security.pkcs12.PKCS12KeyStore.engineLoad(PKCS12KeyStore.java:2159)
        at java.base/sun.security.util.KeyStoreDelegator.engineLoad(KeyStoreDelegator.java:221)
        at java.base/java.security.KeyStore.load(KeyStore.java:1473)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.load(DefaultSslEngineFactory.java:377)
        ... 18 more
Caused by: java.security.UnrecoverableKeyException: failed to decrypt safe contents entry: javax.crypto.BadPaddingException: Given final block not properly padded. Such issues can arise if a bad key is used during decryption.
        ... 22 more
sh-5.1$   
sh-5.1$ 
sh-5.1$ 
sh-5.1$ 
sh-5.1$ cat <<EOF > /tmp/kafka-producer.properties
bootstrap.servers=dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093
security.protocol=SSL
ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
ssl.truststore.password=$(printenv CERTS_STORE_PASSWORD)
EOF
sh-5.1$ cat /tmp/kafka-producer.properties
bootstrap.servers=dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093
security.protocol=SSL
ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
ssl.truststore.password=
sh-5.1$ ./kafka-console-producer.sh \
--producer.config /tmp/kafka-producer.properties \
--topic neft.outbound.kafka.topic
Missing required option(s) [bootstrap-server]
Option                                   Description                            
------                                   -----------                            
--batch-size <Integer: size>             Number of messages to send in a single 
                                           batch if they are not being sent     
                                           synchronously. please note that this 
                                           option will be replaced if max-      
                                           partition-memory-bytes is also set   
                                           (default: 16384)                     
--bootstrap-server <String: server to    REQUIRED unless --broker-list          
  connect to>                              (deprecated) is specified. The server
                                           (s) to connect to. The broker list   
                                           string in the form HOST1:PORT1,HOST2:
                                           PORT2.                               
--broker-list <String: broker-list>      DEPRECATED, use --bootstrap-server     
                                           instead; ignored if --bootstrap-     
                                           server is specified.  The broker     
                                           list string in the form HOST1:PORT1, 
                                           HOST2:PORT2.                         
--compression-codec [String:             The compression codec: either 'none',  
  compression-codec]                       'gzip', 'snappy', 'lz4', or 'zstd'.  
                                           If specified without value, then it  
                                           defaults to 'gzip'                   
--help                                   Print usage information.               
--line-reader <String: reader_class>     The class name of the class to use for 
                                           reading lines from standard in. By   
                                           default each line is read as a       
                                           separate message. (default: kafka.   
                                           tools.                               
                                           ConsoleProducer$LineMessageReader)   
--max-block-ms <Long: max block on       The max time that the producer will    
  send>                                    block for during a send request.     
                                           (default: 60000)                     
--max-memory-bytes <Long: total memory   The total memory used by the producer  
  in bytes>                                to buffer records waiting to be sent 
                                           to the server. This is the option to 
                                           control `buffer.memory` in producer  
                                           configs. (default: 33554432)         
--max-partition-memory-bytes <Integer:   The buffer size allocated for a        
  memory in bytes per partition>           partition. When records are received 
                                           which are smaller than this size the 
                                           producer will attempt to             
                                           optimistically group them together   
                                           until this size is reached. This is  
                                           the option to control `batch.size`   
                                           in producer configs. (default: 16384)
--message-send-max-retries <Integer>     Brokers can fail receiving the message 
                                           for multiple reasons, and being      
                                           unavailable transiently is just one  
                                           of them. This property specifies the 
                                           number of retries before the         
                                           producer give up and drop this       
                                           message. This is the option to       
                                           control `retries` in producer        
                                           configs. (default: 3)                
--metadata-expiry-ms <Long: metadata     The period of time in milliseconds     
  expiration interval>                     after which we force a refresh of    
                                           metadata even if we haven't seen any 
                                           leadership changes. This is the      
                                           option to control `metadata.max.age. 
                                           ms` in producer configs. (default:   
                                           300000)                              
--producer-property <String:             A mechanism to pass user-defined       
  producer_prop>                           properties in the form key=value to  
                                           the producer.                        
--producer.config <String: config file>  Producer config properties file. Note  
                                           that [producer-property] takes       
                                           precedence over this config.         
--property <String: prop>                A mechanism to pass user-defined       
                                           properties in the form key=value to  
                                           the message reader. This allows      
                                           custom configuration for a user-     
                                           defined message reader.              
                                         Default properties include:            
                                          parse.key=false                       
                                          parse.headers=false                   
                                          ignore.error=false                    
                                          key.separator=\t                      
                                          headers.delimiter=\t                  
                                          headers.separator=,                   
                                          headers.key.separator=:               
                                          null.marker=   When set, any fields   
                                           (key, value and headers) equal to    
                                           this will be replaced by null        
                                         Default parsing pattern when:          
                                          parse.headers=true and parse.key=true:
                                           "h1:v1,h2:v2...\tkey\tvalue"         
                                          parse.key=true:                       
                                           "key\tvalue"                         
                                          parse.headers=true:                   
                                           "h1:v1,h2:v2...\tvalue"              
--reader-config <String: config file>    Config properties file for the message 
                                           reader. Note that [property] takes   
                                           precedence over this config.         
--request-required-acks <String:         The required `acks` of the producer    
  request required acks>                   requests (default: -1)               
--request-timeout-ms <Integer: request   The ack timeout of the producer        
  timeout ms>                              requests. Value must be non-negative 
                                           and non-zero. (default: 1500)        
--retry-backoff-ms <Long>                Before each retry, the producer        
                                           refreshes the metadata of relevant   
                                           topics. Since leader election takes  
                                           a bit of time, this property         
                                           specifies the amount of time that    
                                           the producer waits before refreshing 
                                           the metadata. This is the option to  
                                           control `retry.backoff.ms` in        
                                           producer configs. (default: 100)     
--socket-buffer-size <Integer: size>     The size of the tcp RECV size. This is 
                                           the option to control `send.buffer.  
                                           bytes` in producer configs.          
                                           (default: 102400)                    
--sync                                   If set message send requests to the    
                                           brokers are synchronously, one at a  
                                           time as they arrive.                 
--timeout <Long: timeout_ms>             If set and the producer is running in  
                                           asynchronous mode, this gives the    
                                           maximum amount of time a message     
                                           will queue awaiting sufficient batch 
                                           size. The value is given in ms. This 
                                           is the option to control `linger.ms` 
                                           in producer configs. (default: 1000) 
--topic <String: topic>                  REQUIRED: The topic id to produce      
                                           messages to.                         
--version                                Display Kafka version.                 
sh-5.1$ ./kafka-console-producer.sh --bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 --producer.config /tmp/strimzi-connect.properties --topic neft.outbound.kafka.topic
[2026-01-17 07:26:26,752] WARN The path /opt/kafka/init is not a directory (org.apache.kafka.common.config.provider.DirectoryConfigProvider)
org.apache.kafka.common.KafkaException: Failed to construct kafka producer
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:476)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:297)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:324)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:309)
        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:99)
        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
Caused by: org.apache.kafka.common.KafkaException: Failed to create new NetworkClient
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:255)
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:163)
        at org.apache.kafka.clients.producer.KafkaProducer.newSender(KafkaProducer.java:526)
        at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:465)
        ... 5 more
Caused by: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /tmp/kafka/cluster.truststore.p12 of type PKCS12
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.load(DefaultSslEngineFactory.java:380)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.<init>(DefaultSslEngineFactory.java:352)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory.createTruststore(DefaultSslEngineFactory.java:325)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory.configure(DefaultSslEngineFactory.java:169)
        at org.apache.kafka.common.security.ssl.SslFactory.instantiateSslEngineFactory(SslFactory.java:147)
        at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:100)
        at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:70)
        at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:193)
        at org.apache.kafka.common.network.ChannelBuilders.clientChannelBuilder(ChannelBuilders.java:82)
        at org.apache.kafka.clients.ClientUtils.createChannelBuilder(ClientUtils.java:120)
        at org.apache.kafka.clients.ClientUtils.createNetworkClient(ClientUtils.java:224)
        ... 8 more
Caused by: java.io.IOException: keystore password was incorrect
        at java.base/sun.security.pkcs12.PKCS12KeyStore.engineLoad(PKCS12KeyStore.java:2159)
        at java.base/sun.security.util.KeyStoreDelegator.engineLoad(KeyStoreDelegator.java:221)
        at java.base/java.security.KeyStore.load(KeyStore.java:1473)
        at org.apache.kafka.common.security.ssl.DefaultSslEngineFactory$FileBasedStore.load(DefaultSslEngineFactory.java:377)
        ... 18 more
Caused by: java.security.UnrecoverableKeyException: failed to decrypt safe contents entry: javax.crypto.BadPaddingException: Given final block not properly padded. Such issues can arise if a bad key is used during decryption.
        ... 22 more
sh-5.1$ ./kafka-console-producer.sh \
--bootstrap-server dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 \
--topic neft.outbound.kafka.topic
>[2026-01-17 07:26:48,802] WARN [Producer clientId=console-producer] Bootstrap broker dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 (id: -1 rack: null) disconnected (org.apache.kafka.clients.NetworkClient)
[2026-01-17 07:26:49,059] WARN [Producer clientId=console-producer] Bootstrap broker dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 (id: -1 rack: null) disconnected (org.apache.kafka.clients.NetworkClient)
[2026-01-17 07:26:49,344] WARN [Producer clientId=console-producer] Bootstrap broker dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 (id: -1 rack: null) disconnected (org.apache.kafka.clients.NetworkClient)
[2026-01-17 07:26:49,703] WARN [Producer clientId=console-producer] Bootstrap broker dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 (id: -1 rack: null) disconnected (org.apache.kafka.clients.NetworkClient)
[2026-01-17 07:26:50,268] WARN [Producer clientId=console-producer] Bootstrap broker dev-kafka-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9093 (id: -1 rack: null) disconnected (org.apache.kafka.clients.NetworkClient)
sh-5.1$ 
